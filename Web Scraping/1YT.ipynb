{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeUhsBhCayCb",
        "outputId": "1ac00948-22c0-495b-a1b8-29174315d625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting isodate\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate\n",
            "Successfully installed isodate-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install isodate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HhK7ff_aaTs"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "api_key = ''\n",
        "\n",
        "channel_id = 'UC7cs8q-gJRlGwj4A8OmCmXg'\n",
        "\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "\n",
        "\n",
        "def get_channel_metadata(youtube, channel_id):\n",
        "    request = youtube.channels().list(\n",
        "        part=\"snippet,contentDetails,statistics\",\n",
        "        id=channel_id\n",
        "    )\n",
        "    response = request.execute()\n",
        "    item = response['items'][0]\n",
        "\n",
        "    metadata = {\n",
        "        \"Channel_name\": item[\"snippet\"][\"title\"],\n",
        "        \"Subscribers\": item[\"statistics\"][\"subscriberCount\"],\n",
        "        \"Views\": item[\"statistics\"][\"viewCount\"],\n",
        "        \"PublishedAt\": item[\"snippet\"][\"publishedAt\"],\n",
        "        \"Country\": item.get(\"snippet\", {}).get(\"country\", \"N/A\"),\n",
        "        \"Total_videos\": item[\"statistics\"][\"videoCount\"],\n",
        "        \"playlist_id\": item[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "    }\n",
        "    return metadata\n",
        "\n",
        "channel_metadata = get_channel_metadata(youtube, channel_id)\n",
        "channel_df = pd.DataFrame([channel_metadata])\n",
        "\n",
        "channel_df\n",
        "\n",
        "channel_df.to_csv(\"channel_metadata.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import isodate\n",
        "\n",
        "def get_all_videos_with_stats(youtube, playlist_id):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        request = youtube.playlistItems().list(\n",
        "            part=\"snippet\",\n",
        "            playlistId=playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            published_at = item[\"snippet\"][\"publishedAt\"]\n",
        "            video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
        "            video_title = item[\"snippet\"][\"title\"]\n",
        "\n",
        "            stats_response = youtube.videos().list(\n",
        "                part=\"statistics,contentDetails\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            video_data = stats_response['items'][0]\n",
        "            stats = video_data['statistics']\n",
        "            duration_iso = video_data['contentDetails']['duration']\n",
        "            duration_seconds = isodate.parse_duration(duration_iso).total_seconds()\n",
        "\n",
        "            videos.append({\n",
        "                \"video_id\": video_id,\n",
        "                \"video_title\": video_title,\n",
        "                \"published_at\": published_at,\n",
        "                \"view_count\": int(stats.get(\"viewCount\", 0)),\n",
        "                \"like_count\": int(stats.get(\"likeCount\", 0)),\n",
        "                \"comment_count\": int(stats.get(\"commentCount\", 0)),\n",
        "                \"duration_seconds\": duration_seconds\n",
        "            })\n",
        "\n",
        "        next_page_token = response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return pd.DataFrame(videos)\n",
        "\n",
        "playlist_id = channel_df[\"playlist_id\"].iloc[0]\n",
        "df_videos = get_all_videos_with_stats(youtube, playlist_id)\n",
        "\n",
        "df_videos.head(5)\n",
        "\n",
        "df_videos.to_csv(\"videos_data.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "def get_video_comments(youtube, video_id, max_comments=100):\n",
        "    comments = []\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        request = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\"\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "            comments.append({\n",
        "                'video_id': video_id,\n",
        "                'comment': comment\n",
        "            })\n",
        "            if len(comments) >= max_comments:\n",
        "                break\n",
        "\n",
        "        next_page_token = response.get('nextPageToken')\n",
        "        if not next_page_token or len(comments) >= max_comments:\n",
        "            break\n",
        "    return comments\n",
        "\n",
        "all_comments = []\n",
        "for vid in df_videos['video_id']:\n",
        "    comments = get_video_comments(youtube, vid, max_comments=500)\n",
        "    all_comments.extend(comments)\n",
        "\n",
        "df_comments = pd.DataFrame(all_comments)\n",
        "df_comments.to_csv(\"comments.csv\", index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
